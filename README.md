# Fraude de Cr√©dito

## üíº Contexto:
O mercado financeiro √© afetado diariamente por fatores econ√¥micos, culturais, pol√≠ticos e aleat√≥rios (cat√°strofes naturais). Diante dessa grande varia√ß√£o, prever a dire√ß√£o futura do mercado torna-se uma tarefa de extrema dificuldade. Nesse cen√°rio, t√©cnicas estat√≠sticas e matem√°ticas s√£o comumente utilizadas para previs√£o de mercado.

Diante dessas t√©cnicas, os modelos de aprendizado de m√°quina se apresentam como uma das principais ferramentas utilizadas na literatura de predi√ß√£o de movimento de mercados. Neste estudo, foi utilizado o m√©todo Random Forest e Support Vector Machine. 

Como vari√°vel dependente do modelo foi utilizado 1 e 0, representando movimentos de alta e baixa do mercado em $t+1$, respectivamente. Al√©m disso, como vari√°veis explicativas utilizou-se 8 indicadores t√©cnicos, sendo seus valores extra√≠dos tanto na forma cont√≠nua quanto bin√°ria. A avalia√ß√£o de cada modelo considerou cada tipo de vari√°vel independente (cont√≠nua e bin√°ria), proporcionando uma compreens√£o do impacto das mesmas.

Para melhorar a performance do modelo abordou-se a t√©cnica de itera√ß√£o conhecida como GridSearch que busca os melhores par√¢metros para o modelo. Essa abordagem, aliada √† valida√ß√£o cruzada, permitiu a obten√ß√£o de resultados mais robustos e confi√°veis.

### Modelos
#### Floresta Aleat√≥ria
No modelo de aprendizado de floresta aleat√≥ria, as √°rvores que comp√µem a floresta,
s√£o geradas por meio da t√©cnica de bagging. As √°rvores s√£o treinadas com subamostras de
treinos geradas por meio do boostrap e por um n√∫mero x de features (vari√°veis independentes),
que s√£o escolhidas aleatoriamente a cada n√≥ da √°rvore. Essas duas t√©cnicas combinadas geram
√°rvores menos correlacionadas poss√≠veis, resultando numa maior adversidade para o modelo e
consequentemente uma menor vari√¢ncia.

Vale destacar que, a t√©cnica de random subfeatures √© utilizada para evitar a presen√ßa de
vari√°veis independentes excessivamente influentes durante processo de bagging no treinamento.
Ou seja, sem essa t√©cnica, a feature de maior import√¢ncia tender√° aparecer em praticamente
todas as √°rvores, resultando em √°rvores muito similares entre si (JAMES et al., 2013).

Como a t√©cnica de bagging tem como principal caracter√≠sticas a diminui√ß√£o da vari√¢ncia,
ent√£o ser√£o escolhidos par√¢metros para que o modelo base (√°rvore decis√£o) tenha maior vari√¢ncia
poss√≠vel (PRADO, 2018).

<img src="imgs/RF_params.png" align="center" height=auto width=60%/>

- Bootstrap = True: Constr√≥i m√∫ltiplas amostras, com reposi√ß√£o, a partir dos dados de
treinamento, gerando avalia√ß√£o das variabilidades das estima√ß√µes.
- Min_weight_fraction_leaf : Permite definir a fra√ß√£o m√≠nima dos dados necess√°ria para o
n√≥ final ser v√°lido ou n√£o. Isso permite ajustar a complexidade da √°rvore, influenciando
diretamente na sua generaliza√ß√£o.
- Class_weights = balanced_subsample: Ajusta os pesos das classes a fim de lidar com
desbalanceamento de classes nos dados, garantindo que os modelos fracos sejam treinados
com dados equilibrados.
- Max_Features: Limita o n√∫mero de vari√°veis independentes para cada divis√£o de uma
√°rvore. Quando esse par√¢metro √© igual a um, ent√£o a cada n√≥ da √°rvore ser√° escolhida,
aleatoriamente, uma vari√°vel independente, gerando uma maior discrep√¢ncia entre as
√°rvores.
- N_estimator = 1000: Define o n√∫mero de √°rvores para formar a floresta.
- Criterion = Entropy: Crit√©rio de divis√£o dos n√≥s.

Dessa maneira, a diversidade entre as √°rvores permite que elas explorem diferentes
padr√µes nos dados contribuindo de forma mais significativa para agrega√ß√£o final dos modelos.
Al√©m disso, a floresta aleat√≥ria consegue captar os movimentos vol√°teis e complexos do mercado
uma vez que seu algoritmo n√£o faz suposi√ß√µes sobre as distribui√ß√µes das vari√°veis independentes,
gerando mais robustez para o modelo

#### Support Vector Machine
√â um modelo, o qual, seu principio parte de uma reta tracejada, conhecida como hiperplano de separa√ß√£o, que divide os dados entre positivos e negativos. Esse hiperplano √© um
subespa√ßo plano de dimens√£o p ‚Äì 1, onde p √© numero de vari√°veis independentes.

<img src="imgs/svm_esl.png" align="center" height=auto width=60%/>

A ideia de classifica√ß√£o dos dados por meio de um hiperplano se difere totalmente dos
algoritmos que foram apresentados. O hiperplano possui uma margem, conhecida como Maximal
Margin que √© calculada por meio da t√©cnica de "optimal separating hyperplane". Essa t√©cnica
calcula a maior dist√¢ncia min√≠ma entre a observa√ß√£o de treino e o hiperplano, ou seja, a maior
dist√¢ncia m√≠nima entre a separa√ß√£o das classes. As observa√ß√µes que est√£o na fronteira da margem
s√£o chamadas de vetores suportes e s√£o elas que determinam o hiperplano e a margem (JAMES
et al., 2013). Dessa forma, podemos classificar a vari√°vel independente de acordo com o lado
mais pr√≥ximo que ela se encontra da margem, sendo sua classe -1,1.

Support Vector Machine √© considerado uma extens√£o do SVC que aplica um aumento de
dimensionalidade para lidar com vari√°veis as quais n√£o podem ser divididas por um hiperplano
de duas dimens√µes. Esse problema pode ser resolvido adicionando polin√¥mios de diferentes
graus das vari√°veis independentes no modelo. Entretanto, isso geraria um grande n√∫mero de
vari√°veis e consequentemente um maior custo computacional, tornando o treinamento do modelo
praticamente imposs√≠vel. Para superar esse problema, o SVM aplica uma t√©cnica conhecida
como "kernels".

Dessa maneira, a ideia principal do algoritmo √© encontrar uma margem entre os vetores de suporte e o hiperplano que possa gerar a melhor classifica√ß√£o poss√≠vel. Os √∫nicos par√¢metros desse modelo √© a constante C e vari√°vel do kernel.


### Valida√ß√£o Cruzada

#### Problem√°tica do K-Fold
A valida√ß√£o cruzada √© uma t√©cnica muito utilizada na literatura de aprendizado de m√°quina para avaliar o desempenho de um modelo. Neste estudo, a valida√ß√£o cruzada teve papel crucial na avalia√ß√£o dos modelos de treinamento durante a sele√ß√£o de hiperpar√¢metros.

A valida√ß√£o cruzada com K-fold divide os dados em K partes
de tamanhos iguais, chamadas de folds e utiliza parte dos dados dispon√≠veis para ajustar o modelo e outra parte para test√°-lo.

<img src="imgs/K_fold_exemplo.png" align="center" height=auto width=60%/>

Supondo que a base de dados utilizada nesta valida√ß√£o cruzada abranja um per√≠odo de 5
anos, cada fold corresponder√° a um conjunto de informa√ß√µes de 1 ano. Nesse sentido, nota-se
que na primeira itera√ß√£o, o primeiro ano √© utilizado como conjunto de teste, enquanto os outros 4
anos para treinamento. Considerando que todas as configura√ß√µes poss√≠veis s√£o testadas entre os
folds de teste e treinamento, o primeiro ano √© avaliado em apenas um cen√°rio (utilizando anos 2,
3, 4 e 5 como treino), o que pode resultar em um vi√©s e falsas descobertas do modelo. Para uma
avalia√ß√£o mais robusta √© necess√°rio que os folds de teste sejam testados em um conjunto maior
de cen√°rios.

Al√©m disso, caso o modelo utilize vari√°veis independentes com defasagens temporais de
at√© 14 dias, pode-se identificar duas problem√°ticas: (i) √© poss√≠vel que os primeiros 14 dias do
conjunto de teste contenham informa√ß√µes provenientes da base de treinamento; (ii) o in√≠cio do
fold de treinamento que sucede um fold de teste tamb√©m pode conter informa√ß√µes do fold de
teste anterior. Ambas quest√µes levam a um poss√≠vel vazamento de dados e podem comprometer
a capacidade de generaliza√ß√£o do modelo.

#### Purge

Como solu√ß√£o para o vazamento de dados, Prado (2018) prop√¥s a t√©cnica de Purge. Essa
t√©cnica, lida diretamente com os 2 problemas, por meio da cria√ß√£o de um intervalo entre folds
de treino e teste. O gr√°fico a seguir Pre√ßo x Ano, exemplifica a t√©cnica de purge:

<img src="imgs/cv_prado_exemplo.png" align="center" height=auto width=60%/>

Nessa figura nota-se, que o conjunto de teste (test) antecede e sucede um conjunto de
treinamento (train), caindo na problem√°tica de vazamento de dados. No entanto, ao criar o
intervalo (overlap) entre os folds de treino e teste, o vazamento de dados √© evitado.

#### Combinatorial Purged Cross-Validation (CPCV)

Al√©m de resolver a problem√°tica de vazamento de dados, Prado (2018) prop√¥s uma
valida√ß√£o cruzada mais robusta e menos suscet√≠vel ao sobreajuste, conhecida como "Combinatorial Purged Cross-Validation (CPCV)". O algoritmo funciona de maneira parecida com
valida√ß√£o cruzada K-fold, entretanto, podemos ter mais de um fold de teste. Na Figura 6 temos
um exemplo de CPCV em que os dados s√£o divididos em 6 folds, com 4 de treinamento e 2 de
teste, gerando um total de 15 combina√ß√µes diferentes a serem avaliadas.

<img src="imgs/CPCV.png" align="center" height=auto width=60%/>

### Dados

20 anos de dados di√°rios do Ibovespa foram utilizados, entre per√≠odo de 2002 e 2022.
Esse per√≠odo cont√©m as principais crises financeiras: Subprime(2008) e Covid-19(2020). Os
dados foram extra√≠dos por meio de uma biblioteca do python chamada yfinance, gerando uma base de dados com 4949 dias, sendo composta por 52,25% movimentos de altas e 47,75% de
baixa.

#### Vari√°vel Dependente(Alvo)

A vari√°vel dependente do modelo ser√° o fechamento do Ibovespa no per√≠odo t + 1. Nesse
contexto, se o fechamento do Ibovespa no dia seguinte indicar um movimento de alta, a vari√°vel
ter√° valor 1, caso contr√°rio (movimento de baixa) ter√° valor 0. Portanto, a vari√°vel de sa√≠da ser√°
uma vari√°vel bin√°ria


#### Vari√°vel Independente(Features)

As vari√°veis explicativas do modelo ser√£o derivadas de 8 indicadores t√©cnicos utilizados
na literatura de Kara, Boyacioglu e Baykan (2011), assim como foi utilizado por Patel et
al. (2015). Muitos fundos de investimento e investidores aceitam e utilizam os crit√©rios dos
indicadores t√©cnicos na tomada de decis√£o de investimento (KIM, 2003).
Inicialmente, os indicadores t√©cnicos s√£o obtidos como valores cont√≠nuos. A fim de
explorar os crit√©rios dos indicadores eles ser√£o transformados em vari√°veis bin√°rias, sendo 1
caso indiquem movimento de alta e 0 para movimento de baixa.
Essa abordagem segue a metodologia utilizada em Patel et al. (2015) e ser√° aplicada na
an√°lise dos modelos. Portanto, os modelos ser√£o testados tanto com vari√°veis cont√≠nuas quanto
com vari√°veis binarias, permitindo a compara√ß√£o de desempenho entre ambas.

### Resultados

O modelo que melhor performou foi de SVM, superando o ibovespa no per√≠odo de 2018~2023.


<img src="imgs/Retorno_SVM.png" align="center" height=auto width=100%/>





## Contato
bernardo.alemar@hotmail.com

# Executar o Script em sua m√°quina local
## Pr√©-requisitos:

Antes de come√ßar, certifique-se de ter o seguinte instalado em sua m√°quina:

- Python 3.10.12
- pip (gerenciador de pacotes Python)
- Git (ferramenta de controle de vers√£o)

Uma vez que voc√™ tenha isso instalado, abra um terminal em sua m√°quina local e execute os seguintes comandos:

1. **Clone o reposit√≥rio:**
   ```bash
   git clone https://github.com/bAlemar/Prevendo-Movimento-do-Ibovespa.git

2. **Navegue at√© o diret√≥rio do reposit√≥rio clonado:**
   ```bash
   cd Prevendo-Movimento-do-Ibovespa

3. **Crie um ambiente virtual:**
   ```bash
    python -m venv ambiente_virtual

4. **Ative o ambiente virtual:**

   **4.1 Linux**
   ```bash
    source ambiente_virtual/bin/activate
   ```
   **4.2 Windows**
   ```bash
    ambiente_virtual\Scripts\activate

5. **Instale as Depend√™ncias:**
- Instale de acordo com Dashboard que deseja utilizar.
   ```bash
    pip install -r requeriments.txt 

    
    